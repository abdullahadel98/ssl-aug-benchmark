version: '3.8'

services:
  python-gpu-container-gpu0:
    build:
      context: . # Path to the Dockerfile (current directory)
      dockerfile: Dockerfile
      args:
        USER_ID: ${UID:-1000}
        GROUP_ID: ${GID:-1000}
    user: "${UID:-1000}:${GID:-1000}"
    shm_size: '128g'
    runtime: nvidia
    environment:
      NVIDIA_VISIBLE_DEVICES: "0"  # Restrict to GPU 0
      CUDA_HOME: "/usr/local/cuda"
      LD_LIBRARY_PATH: "/usr/local/lib:/usr/lib:/lib:$LD_LIBRARY_PATH"
    volumes:
      - /data/siedel/datasets:/data
      - /home/siedel/data/ImageNet:/data/ImageNet
      - /home/siedel/data/TinyImageNet:/data/TinyImageNet
      - /home/siedel/trained_models:/trained_models
      - ./results:/workspace/results
      - ./experiments/configs:/workspace/experiments/configs
      - ./run_0.py:/workspace/run_0.py
      - ./run_1.py:/workspace/run_1.py
      - ./run_2.py:/workspace/run_2.py
      - ./run_3.py:/workspace/run_3.py
      - ./run_4.py:/workspace/run_4.py
      - ./run_5.py:/workspace/run_5.py
      - ./run_6.py:/workspace/run_6.py
      - ./run_7.py:/workspace/run_7.py
    #command: python run_exp.py  # Run the main script for this container
    tty: true

  python-gpu-container-gpu1:
    extends:
      service: python-gpu-container-gpu0
    environment:
      NVIDIA_VISIBLE_DEVICES: "1"  # Restrict to GPU 1
    #command: python run_exp_1.py  # Run a different script for this container
    tty: true

  python-gpu-container-gpu2:
    extends:
      service: python-gpu-container-gpu0
    environment:
      NVIDIA_VISIBLE_DEVICES: "2"  # Restrict to GPU 2
    #command: python run_exp_2.py  # Run a different script for this container
    tty: true

  python-gpu-container-gpu3:
    extends:
      service: python-gpu-container-gpu0
    environment:
      NVIDIA_VISIBLE_DEVICES: "3"  # Restrict to GPU 3
    #command: python run_exp_3.py  # Run a different script for this container
    tty: true

  python-gpu-container-gpu4:
    extends:
      service: python-gpu-container-gpu0
    environment:
      NVIDIA_VISIBLE_DEVICES: "4"  # Restrict to GPU 4
    #command: python run_exp_4.py  # Run a different script for this container
    tty: true

  python-gpu-container-gpu5:
    extends:
      service: python-gpu-container-gpu0
    environment:
      NVIDIA_VISIBLE_DEVICES: "5"  # Restrict to GPU 3
    #command: python run_exp_5.py  # Run a different script for this container
    tty: true

  python-gpu-container-gpu6:
    extends:
      service: python-gpu-container-gpu0
    environment:
      NVIDIA_VISIBLE_DEVICES: "6"  # Restrict to GPU 3
    #command: python run_exp_6.py  # Run a different script for this container
    tty: true

  python-gpu-container-gpu7:
    extends:
      service: python-gpu-container-gpu0
    environment:
      NVIDIA_VISIBLE_DEVICES: "7"  # Restrict to GPU 3
    #command: python run_exp_7.py  # Run a different script for this container
    tty: true
